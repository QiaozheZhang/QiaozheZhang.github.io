---
layout: page
title: About
permalink: /index.html
---

<img style="float:right; padding-left:10px" src="images/selfandcat.jpg" width="220" height="220">

I am a Ph.D. student in [EIC](https://english.eic.hust.edu.cn){:target="_blank" rel="noopener"} at [Huazhong University of Science and Technology](https://english.hust.edu.cn/){:target="_blank" rel="noopener"}, supervised by [Prof. Jun Sun](https://hust.teacher.360eol.com/teacherBasic/preview?teacherType=&teacherId=15979){:target="_blank" rel="noopener"} and [Prof. Yingzhuang Liu](https://hust.teacher.360eol.com/teacherBasic/preview?teacherType=&teacherId=15939){:target="_blank" rel="noopener"}. 

Previously, I received my B.Eng degree (2014-2018) in Electronic Information Engineering from [Huazhong University of Science and Technology](https://english.hust.edu.cn/){:target="_blank" rel="noopener"}, worked with [Prof. Xin Yang](https://sites.google.com/view/xinyang/home){:target="_blank" rel="noopener"}.

# Research Interests

My research interests broadly lie in the theoretical understanding of deep learning. I am particularly fascinated by simple yet principled approaches that can shed light on the fundamental capabilities and limitations of modern models, and I aim to develop frameworks that bridge theory and practiceâ€”both explaining why existing methods work and guiding the design of future ones.

These days, I am mostly drawn by three interrelated directions: model compression and capacity, generalization, and robustness. These aspects are central to efficiency, reliability, and interpretability of deep learning, and I am especially interested in developing theoretical tools that help us better understand the trade-offs between them.

<!-- News -->

# Publications

<!--<span class="badge">J</span> Journal <span class="badge">C</span> Conference <br>-->

{% include paper_md/renyi_sharpness.md %}

{% include paper_md/pruning_limit.md %}

{% include paper_md/mmil.md %}

{% include paper_md/gan_slam.md %}

# Services
**Conference Reviewers**
- Neural Information Processing Systems (NeurIPS) 2024 - 2025
- International Conference on Learning Representations (ICLR) 2025 - 2026
- International Conference on Machine Learning (ICML) 2025 - 2026
